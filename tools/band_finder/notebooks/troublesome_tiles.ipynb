{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distinguished-birth",
   "metadata": {},
   "source": [
    "# Troublesome Tiles\n",
    "\n",
    "The naive approach of using np.interp to match adjacent full-sensor image tiles, treating them as grayscale images, works surprisingly well.  But it fails miserably in some cases.\n",
    "\n",
    "One of the worst failures is `pano_188_3_668275957.301_NAVCAM_RIGHT`.  It is assembled from these tile images:\n",
    "\n",
    "```\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_01_0LLJ (0, 0, 1288, 968)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_02_0LLJ (1272, 0, 1296, 968)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_03_0LLJ (2552, 0, 1296, 968)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_04_0LLJ (3832, 0, 1288, 968)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_05_0LLJ (0, 952, 1288, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_06_0LLJ (1272, 952, 1296, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_07_0LLJ (2552, 952, 1296, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_08_0LLJ (3832, 952, 1288, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_09_0LLJ (0, 1912, 1288, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_10_0LLJ (1272, 1912, 1296, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_11_0LLJ (2552, 1912, 1296, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_12_0LLJ (3832, 1912, 1288, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_13_0LLJ (0, 2872, 1288, 968)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_14_0LLJ (1272, 2872, 1296, 968)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_15_0LLJ (2552, 2872, 1296, 968)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_16_0LLJ (3832, 2872, 1288, 968)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-delta",
   "metadata": {},
   "source": [
    "I've cached a copy of it here.\n",
    "\n",
    "![pano_188...](./images/pano_188_3_668275957.301_NAVCAM_RIGHT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-acrylic",
   "metadata": {},
   "source": [
    "Why does this mapping fail so miserably?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "metric-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color, io\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "from band_finder.image_db import ImageDB\n",
    "from band_finder.image_cache import ImageCache\n",
    "from band_finder.tile_matcher import TileMatcher\n",
    "from band_finder.bayer_to_rgb import bayer_to_rgb\n",
    "\n",
    "examples_dir = Path(\"../examples\").resolve()\n",
    "\n",
    "db_path = list(examples_dir.glob(\"*.db\"))[0]\n",
    "assert db_path.exists()\n",
    "\n",
    "image_db = ImageDB(db_path)\n",
    "\n",
    "cache_dir = examples_dir / \"image_cache\"\n",
    "assert cache_dir.exists()\n",
    "\n",
    "image_cache = ImageCache(image_db, cache_dir)\n",
    "\n",
    "def get_rgb_image(image_id):\n",
    "    image = image_cache.get_image(image_id)\n",
    "    # If it is a bayer image, convert it to RGB.\n",
    "    if image_id[2:3] == \"E\":\n",
    "        image = bayer_to_rgb(image)\n",
    "    return image\n",
    "    \n",
    "def get_lab_image(image_id):        \n",
    "    return color.rgb2lab(get_rgb_image(image_id))\n",
    "\n",
    "class TileMatcherBuilder:\n",
    "    def __init__(self, get_image=get_lab_image):\n",
    "        self._get_image = get_image\n",
    "        self._matcher = TileMatcher()\n",
    "        # Original, unadjusted images:\n",
    "        self._image_ids = []\n",
    "        \n",
    "    def add_tile(self, image_id, bbox):\n",
    "        self._image_ids.append(image_id)\n",
    "\n",
    "        image = self._get_image(image_id)\n",
    "        origin = bbox[:2]\n",
    "        print(\"Add\", image_id, \"at\", origin)\n",
    "\n",
    "        self._matcher.add(image, origin)\n",
    "\n",
    "    def add_test_tiles(self):\n",
    "        add = self.add_tile\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_01_0LLJ\", (0, 0, 1288, 968))\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_02_0LLJ\", (1272, 0, 1296, 968))\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_03_0LLJ\", (2552, 0, 1296, 968))\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_04_0LLJ\", (3832, 0, 1288, 968))\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_05_0LLJ\", (0, 952, 1288, 976))\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_06_0LLJ\", (1272, 952, 1296, 976))\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_07_0LLJ\", (2552, 952, 1296, 976))\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_08_0LLJ\", (3832, 952, 1288, 976))\n",
    "        \n",
    "    def get_composite(self):\n",
    "        return self._matcher.composite()\n",
    "    \n",
    "    def show_originals(self):\n",
    "        num_images = len(self._image_ids)\n",
    "        num_cols = 4\n",
    "        num_rows = num_images // num_cols\n",
    "        if num_rows * num_cols < num_images:\n",
    "            num_rows += 1\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, squeeze=False)\n",
    "        fig.set_tight_layout(True)\n",
    "        ix = iy = 0\n",
    "        for image_id in self._image_ids:\n",
    "            image = get_rgb_image(image_id)\n",
    "            ax = axes[iy][ix]\n",
    "            ax.set_axis_off()\n",
    "            ax.imshow(image)\n",
    "            ix += 1\n",
    "            if ix >= num_cols:\n",
    "                ix = 0\n",
    "                iy += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-revision",
   "metadata": {},
   "source": [
    "Let's try to re-tile a portion of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "infinite-novelty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_01_0LLJ at (0, 0)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_02_0LLJ at (1272, 0)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_03_0LLJ at (2552, 0)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_04_0LLJ at (3832, 0)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_05_0LLJ at (0, 952)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_06_0LLJ at (1272, 952)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_07_0LLJ at (2552, 952)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_08_0LLJ at (3832, 952)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670e2729fae146dc8186da67b566ca44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "builder = TileMatcherBuilder()\n",
    "builder.add_test_tiles()\n",
    "builder.show_originals()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "promising-strip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescale: channel 0 is 0.0...98.16679382324219.\n",
      "Rescale: channel 1 is -17.54530906677246...22.40850067138672.\n",
      "Rescale: Adjusted 1 to -1.0...1.0.\n",
      "Rescale: channel 2 is 0.0...43.117774963378906.\n",
      "Rescale: Adjusted 2 to -1.0...1.0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603f046ae1ee467cbe85b79b9044ec5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12c0f4640>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the lab values are in range.\n",
    "def rescale_channel(image, channel, min_valid, max_valid):\n",
    "    curr_values = image[:, :, channel]\n",
    "    max_in = np.max(curr_values)\n",
    "    min_in = np.min(curr_values)\n",
    "    print(f\"Rescale: channel {channel} is {min_in}...{max_in}.\")\n",
    "    \n",
    "    if (max_in > max_valid) or (min_in < min_valid):\n",
    "        d_in = max_in - min_in\n",
    "        d_out = max_valid - min_valid\n",
    "        scale = d_out / d_in\n",
    "        new_values = (curr_values - min_in) * scale + min_valid\n",
    "        image[:, :, channel] = new_values\n",
    "        \n",
    "        print(f\"Rescale: Adjusted {channel} to {np.min(new_values)}...{np.max(new_values)}.\")\n",
    "\n",
    "def clip_channel(image, channel, min_valid, max_valid):\n",
    "    curr_values = image[:, :, channel]\n",
    "    curr_values[curr_values > max_valid] = max_valid\n",
    "    curr_values[curr_values < min_valid] = min_valid\n",
    "    image[:, :, channel] = curr_values\n",
    "\n",
    "def rescale_lab(image):\n",
    "    rescale_channel(image, 0, 0.0, 100.0)\n",
    "    rescale_channel(image, 1, -1.0, 1.0)\n",
    "    rescale_channel(image, 2, -1.0, 1.0)\n",
    "    \n",
    "\n",
    "lab_image_data = builder.get_composite()\n",
    "rescale_lab(lab_image_data)\n",
    "\n",
    "fig, axes = plt.subplots(1, 1)\n",
    "axes.imshow(img_as_ubyte(color.lab2rgb(lab_image_data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-piano",
   "metadata": {},
   "source": [
    "**Blegh.**  Do things look any better if I stick to RGB throughout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coordinated-boards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_01_0LLJ at (0, 0)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_02_0LLJ at (1272, 0)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_03_0LLJ at (2552, 0)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_04_0LLJ at (3832, 0)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_05_0LLJ at (0, 952)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_06_0LLJ at (1272, 952)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_07_0LLJ at (2552, 952)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_08_0LLJ at (3832, 952)\n",
      "Rescale: channel 0 is 0.0...98.16679382324219.\n",
      "Rescale: channel 1 is -17.54530906677246...22.40850067138672.\n",
      "Rescale: Adjusted 1 to 0.0...255.00001525878906.\n",
      "Rescale: channel 2 is 0.0...43.117774963378906.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4ff9b6736c4402abed4cc4df3458de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12c134370>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_builder = TileMatcherBuilder(get_image=get_rgb_image)\n",
    "rgb_builder.add_test_tiles()\n",
    "rgb_image_data = builder.get_composite()\n",
    "\n",
    "def rescale_rgb(image):\n",
    "    for channel, cmin, cmax in [\n",
    "        [0, 0, 255],\n",
    "        [1, 0, 255],\n",
    "        [2, 0, 255]\n",
    "    ]:\n",
    "        rescale_channel(image, channel, cmin, cmax)\n",
    "\n",
    "rescale_rgb(rgb_image_data)\n",
    "# TileMatcher always produces composites with float64 values.\n",
    "rgb_fig, rgb_axes = plt.subplots(1, 1)\n",
    "rgb_axes.imshow(img_as_ubyte(rgb_image_data.astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-bulletin",
   "metadata": {},
   "source": [
    "Nope.\n",
    "\n",
    "I think the problem in this case is that the first column of the second row is an incomplete tile image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-optimum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
