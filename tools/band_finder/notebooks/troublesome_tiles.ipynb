{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "refined-promise",
   "metadata": {},
   "source": [
    "# Troublesome Tiles\n",
    "\n",
    "The naive approach of using np.interp to match adjacent full-sensor image tiles, treating them as grayscale images, works surprisingly well.  But it fails miserably in some cases.\n",
    "\n",
    "One of the worst failures is `pano_188_3_668275957.301_NAVCAM_RIGHT`.  It is assembled from these tile images:\n",
    "\n",
    "```\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_01_0LLJ (0, 0, 1288, 968)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_02_0LLJ (1272, 0, 1296, 968)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_03_0LLJ (2552, 0, 1296, 968)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_04_0LLJ (3832, 0, 1288, 968)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_05_0LLJ (0, 952, 1288, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_06_0LLJ (1272, 952, 1296, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_07_0LLJ (2552, 952, 1296, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_08_0LLJ (3832, 952, 1288, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_09_0LLJ (0, 1912, 1288, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_10_0LLJ (1272, 1912, 1296, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_11_0LLJ (2552, 1912, 1296, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_12_0LLJ (3832, 1912, 1288, 976)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_13_0LLJ (0, 2872, 1288, 968)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_14_0LLJ (1272, 2872, 1296, 968)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_15_0LLJ (2552, 2872, 1296, 968)\n",
    "Tile NRE_0015_0668275956_042ECM_N0030188NCAM00400_16_0LLJ (3832, 2872, 1288, 968)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-chapter",
   "metadata": {},
   "source": [
    "I've cached a copy of it here.\n",
    "\n",
    "![pano_188...](./images/pano_188_3_668275957.301_NAVCAM_RIGHT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-evaluation",
   "metadata": {},
   "source": [
    "Why does this mapping fail so miserably?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proper-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color, io\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "from band_finder.image_db import ImageDB\n",
    "from band_finder.image_cache import ImageCache\n",
    "from band_finder.tile_matcher import TileMatcher\n",
    "from band_finder.bayer_to_rgb import bayer_to_rgb\n",
    "\n",
    "examples_dir = Path(\"../examples\").resolve()\n",
    "\n",
    "db_path = list(examples_dir.glob(\"*.db\"))[0]\n",
    "assert db_path.exists()\n",
    "\n",
    "image_db = ImageDB(db_path)\n",
    "\n",
    "cache_dir = examples_dir / \"image_cache\"\n",
    "assert cache_dir.exists()\n",
    "\n",
    "image_cache = ImageCache(image_db, cache_dir)\n",
    "\n",
    "def get_rgb_image(image_id):\n",
    "    image = image_cache.get_image(image_id)\n",
    "    # If it is a bayer image, convert it to RGB.\n",
    "    if image_id[2:3] == \"E\":\n",
    "        image = bayer_to_rgb(image)\n",
    "    return image\n",
    "    \n",
    "def get_lab_image(image_id):        \n",
    "    return color.rgb2lab(get_rgb_image(image_id))\n",
    "\n",
    "class TileMatcherBuilder:\n",
    "    def __init__(self, get_image=get_lab_image):\n",
    "        self._get_image = get_image\n",
    "        self._matcher = TileMatcher()\n",
    "        # Original, unadjusted images:\n",
    "        self._image_ids = []\n",
    "        \n",
    "    def add_tile(self, image_id, bbox):\n",
    "        self._image_ids.append(image_id)\n",
    "\n",
    "        image = self._get_image(image_id)\n",
    "        origin = bbox[:2]\n",
    "        print(\"Add\", image_id, \"at\", origin)\n",
    "\n",
    "        self._matcher.add(image, origin)\n",
    "\n",
    "    def add_test_tiles(self):\n",
    "        add = self.add_tile\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_01_0LLJ\", (0, 0, 1288, 968))\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_02_0LLJ\", (1272, 0, 1296, 968))\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_03_0LLJ\", (2552, 0, 1296, 968))\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_04_0LLJ\", (3832, 0, 1288, 968))\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_05_0LLJ\", (0, 952, 1288, 976))\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_06_0LLJ\", (1272, 952, 1296, 976))\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_07_0LLJ\", (2552, 952, 1296, 976))\n",
    "        add(\"NRE_0015_0668275956_042ECM_N0030188NCAM00400_08_0LLJ\", (3832, 952, 1288, 976))\n",
    "        \n",
    "    def get_composite(self):\n",
    "        return self._matcher.composite()\n",
    "    \n",
    "    def show_originals(self):\n",
    "        num_images = len(self._image_ids)\n",
    "        num_cols = 4\n",
    "        num_rows = num_images // num_cols\n",
    "        if num_rows * num_cols < num_images:\n",
    "            num_rows += 1\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, squeeze=False)\n",
    "        fig.set_tight_layout(True)\n",
    "        ix = iy = 0\n",
    "        for image_id in self._image_ids:\n",
    "            image = get_rgb_image(image_id)\n",
    "            ax = axes[iy][ix]\n",
    "            ax.set_axis_off()\n",
    "            ax.imshow(image)\n",
    "            ix += 1\n",
    "            if ix >= num_cols:\n",
    "                ix = 0\n",
    "                iy += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-kruger",
   "metadata": {},
   "source": [
    "Let's try to re-tile a portion of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continuous-calendar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_01_0LLJ at (0, 0)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_02_0LLJ at (1272, 0)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_03_0LLJ at (2552, 0)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_04_0LLJ at (3832, 0)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_05_0LLJ at (0, 952)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_06_0LLJ at (1272, 952)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_07_0LLJ at (2552, 952)\n",
      "Add NRE_0015_0668275956_042ECM_N0030188NCAM00400_08_0LLJ at (3832, 952)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf9b9330499407383c127ca6ba02ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "builder = TileMatcherBuilder()\n",
    "builder.add_test_tiles()\n",
    "builder.show_originals()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "entire-steps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescale: channel 0 is 0.0...99.71771240234375.\n",
      "Rescale: channel 1 is -40.673431396484375...48.06147384643555.\n",
      "Rescale: channel 2 is -30.578603744506836...69.52827453613281.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45d620cbd4240afbf88345507f2f692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12ecd8a90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the lab values are in range.\n",
    "def rescale_channel(image, channel, min_valid, max_valid):\n",
    "    curr_values = image[:, :, channel]\n",
    "    max_in = np.max(curr_values)\n",
    "    min_in = np.min(curr_values)\n",
    "    print(f\"Rescale: channel {channel} is {min_in}...{max_in}.\")\n",
    "    \n",
    "    if (max_in > max_valid) or (min_in < min_valid):\n",
    "        d_in = max_in - min_in\n",
    "        d_out = max_valid - min_valid\n",
    "        scale = d_out / d_in\n",
    "        new_values = (curr_values - min_in) * scale + min_valid\n",
    "        image[:, :, channel] = new_values\n",
    "        \n",
    "        print(f\"Rescale: Adjusted {channel} to {np.min(new_values)}...{np.max(new_values)}.\")\n",
    "\n",
    "def clip_channel(image, channel, min_valid, max_valid):\n",
    "    curr_values = image[:, :, channel]\n",
    "    curr_values[curr_values > max_valid] = max_valid\n",
    "    curr_values[curr_values < min_valid] = min_valid\n",
    "    image[:, :, channel] = curr_values\n",
    "\n",
    "def rescale_lab(image):\n",
    "    rescale_channel(image, 0, 0.0, 100.0)\n",
    "    rescale_channel(image, 1, -127.0, 128.0)\n",
    "    rescale_channel(image, 2, -128.0, 127.0)\n",
    "    \n",
    "\n",
    "lab_image_data = builder.get_composite()\n",
    "rescale_lab(lab_image_data)\n",
    "\n",
    "fig, axes = plt.subplots(1, 1)\n",
    "axes.imshow(img_as_ubyte(color.lab2rgb(lab_image_data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-fight",
   "metadata": {},
   "source": [
    "What am I doing wrong?  I think the problem for the second tile row involves the incomplete image data in column 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stable-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from band_finder.image_matcher import ChannelAdjuster, ImageMatcher\n",
    "from band_finder.tile_image_grid import TileImageGrid, Edge\n",
    "\n",
    "top_image_id = \"NRE_0015_0668275956_042ECM_N0030188NCAM00400_01_0LLJ\"\n",
    "bottom_image_id = \"NRE_0015_0668275956_042ECM_N0030188NCAM00400_05_0LLJ\"\n",
    "\n",
    "top_lab = get_lab_image(top_image_id)\n",
    "bottom_lab = get_lab_image(bottom_image_id)\n",
    "\n",
    "tiles_by_origin = {\n",
    "    (0, 0): top_lab,\n",
    "    (0, 952): bottom_lab\n",
    "}\n",
    "\n",
    "tig = TileImageGrid(tiles_by_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "downtown-phrase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926985296a924019861818fa4be83895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For visual verification, here are the RGB representations of the images.\n",
    "def show_image_col(images):\n",
    "    fig = plt.figure(tight_layout=True)\n",
    "    \n",
    "    num_images = len(images)\n",
    "    all_axes = fig.subplots(num_images, 1, squeeze=False)\n",
    "    \n",
    "    for image, row in zip(images, all_axes):\n",
    "        axes = row[0]\n",
    "        axes.set_axis_off()\n",
    "        axes.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "def show_lab_image_col(lab_images):\n",
    "    images = [img_as_ubyte(color.lab2rgb(image)) for image in lab_images]\n",
    "    show_image_col(images)\n",
    "\n",
    "show_lab_image_col([top_lab, bottom_lab])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "happy-detroit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c9f0fcf48b4a7aad3dfa58d6ab0539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edge_of_top = tig.edge(0, 0, Edge.BOTTOM)\n",
    "edge_of_bottom = tig.edge(0, 1, Edge.TOP)\n",
    "\n",
    "show_lab_image_col([edge_of_top, edge_of_bottom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intended-habitat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a06e2a58f7d478f870fd0d257b56db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_mapping(src, targ):\n",
    "    # Yep, a bit more encapsulation violation...\n",
    "    fig = plt.figure()\n",
    "    axes = fig.subplots(1, 1)\n",
    "    axes.plot(src, targ)\n",
    "    axes.set_xlabel(\"Source\")\n",
    "    axes.set_xlim((0, 100))\n",
    "    axes.set_ylabel(\"Target\")\n",
    "    axes.set_ylim((0, 100))\n",
    "    plt.show()\n",
    "\n",
    "def show_adjuster_vals():\n",
    "    matcher = ImageMatcher(edge_of_bottom, edge_of_top)\n",
    "    # Get the first (L) channel adjuster.\n",
    "    lchan = matcher._adjusters[0]\n",
    "    show_mapping(lchan._osrc, lchan._otarg)\n",
    "\n",
    "show_adjuster_vals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "amended-logan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd70eef32394bedbdd8f33223fa3cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Does the adjuster do a good job on the edge of the bottom image?\n",
    "\n",
    "def show_adjusted_edge_of_bottom():\n",
    "    matcher = ImageMatcher(edge_of_bottom, edge_of_top)\n",
    "    # Get the first (L) channel adjuster.\n",
    "    lchan = matcher._adjusters[0]\n",
    "    \n",
    "    adjusted = edge_of_bottom.copy()\n",
    "    lchan.adjust(adjusted)\n",
    "    \n",
    "    show_lab_image_col([edge_of_top, edge_of_bottom, adjusted])\n",
    "\n",
    "show_adjusted_edge_of_bottom()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "loaded-statistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0297ae0986214e3ea8670e2944324460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_adjusted_bottom_tile():\n",
    "    matcher = ImageMatcher(edge_of_bottom, edge_of_top)\n",
    "    adjusted = matcher.adjusted(bottom_lab)\n",
    "    show_lab_image_col([bottom_lab, adjusted])\n",
    "    \n",
    "show_adjusted_bottom_tile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-paragraph",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
